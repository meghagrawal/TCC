{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwo0fjVa4F4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "265bd1d2-59ed-4759-8a32-f07b8daf76be"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPrv7jYy4UAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43fdf8d5-470c-405c-eeeb-f3938e2cc4c1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "#from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Convolution1D\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "import sys\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK-HmkfB4aAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d54d7cf6-e879-4a72-a47b-84a75d25be44"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZiIfGFa4dAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82fe21d7-b47c-455e-a123-fe7a5e9c20e4"
      },
      "source": [
        "\n",
        "# load data\n",
        "\n",
        "data= pd.read_csv('drive/My Drive/TCC/Twitter data/testPostAnn.csv')\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIc0WKzcBybu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fbd5dce3-425c-40c4-b64d-b08ac406fa28"
      },
      "source": [
        "#data=data.dropna(0, 'any')\n",
        "data=data.fillna(0)\n",
        "data.isnull().sum()\n",
        "#data.head(5)\n",
        "#data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text             0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeS-I8pACSMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "839c9cda-f03c-4b58-ff13-c67c7825e789"
      },
      "source": [
        "data.astype({\"toxic\":int, \"severe_toxic\":int, \"threat\":int, \"identity_hate\":int, \"obscene\":int, \"insult\":int})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You mean to say Ankit Sharma who was stabbed 4...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@sardesairajdeep Not rooting for Kapil Mishra ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @OpIndia_com: After WSJ, Jansatta misquotes...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Saurabhk4u: When #SwaraBhasker and #Jafrab...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @abhishekangad: Intelligence Bureau Securit...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>RT @JantaKaReporter: Centre should be held res...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>RT @tufailelif: \"Kapil Mishra, a local politic...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>RT @zkhan1259: How do you sleep at night @Delh...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>RT @ANI: #WATCH Delhi: National Security Advis...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>RT @the_hindu: The Delhi Police told the MHA t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...  identity_hate\n",
              "0    You mean to say Ankit Sharma who was stabbed 4...  ...              0\n",
              "1    @sardesairajdeep Not rooting for Kapil Mishra ...  ...              0\n",
              "2    RT @OpIndia_com: After WSJ, Jansatta misquotes...  ...              0\n",
              "3    RT @Saurabhk4u: When #SwaraBhasker and #Jafrab...  ...              1\n",
              "4    RT @abhishekangad: Intelligence Bureau Securit...  ...              0\n",
              "..                                                 ...  ...            ...\n",
              "995  RT @JantaKaReporter: Centre should be held res...  ...              0\n",
              "996  RT @tufailelif: \"Kapil Mishra, a local politic...  ...              0\n",
              "997  RT @zkhan1259: How do you sleep at night @Delh...  ...              0\n",
              "998  RT @ANI: #WATCH Delhi: National Security Advis...  ...              0\n",
              "999  RT @the_hindu: The Delhi Police told the MHA t...  ...              0\n",
              "\n",
              "[1000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS8diiIL4lmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4df3aa6b-c9f6-4164-e96a-5f1cc5381811"
      },
      "source": [
        "labels=data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
        "labels.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
              "0      0.0           0.0      0.0     0.0     0.0            0.0\n",
              "1      0.0           0.0      0.0     0.0     0.0            0.0\n",
              "2      0.0           0.0      0.0     0.0     0.0            0.0\n",
              "3      1.0           0.0      0.0     0.0     0.0            1.0\n",
              "4      0.0           0.0      0.0     0.0     0.0            0.0\n",
              "..     ...           ...      ...     ...     ...            ...\n",
              "995    0.0           0.0      0.0     0.0     0.0            0.0\n",
              "996    0.0           0.0      0.0     0.0     0.0            0.0\n",
              "997    0.0           0.0      0.0     0.0     0.0            0.0\n",
              "998    0.0           0.0      0.0     0.0     0.0            0.0\n",
              "999    0.0           0.0      0.0     0.0     0.0            0.0\n",
              "\n",
              "[1000 rows x 6 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXey2v2X4myP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating input and output set\n",
        "X = data['text']\n",
        "#sentences = list(data[\"comment_text\"])\n",
        "#for sen in sentences:\n",
        "#    X.append(preprocess_text(sen))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhjZFus-9tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test=pd.DataFrame()\n",
        "predictions=pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hgi_eEz68Q0",
        "colab_type": "text"
      },
      "source": [
        "1. Toxic Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zs0XdJS7FEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=labels['toxic'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irmGLgma5Bfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lc8WB-0-t4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test['toxic']=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5wIf9KR7KpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40K2bu3y9F0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions['toxic']= naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqxXEiCM65uP",
        "colab_type": "text"
      },
      "source": [
        "2. severe_toxic class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Vpy70XM93fL",
        "colab": {}
      },
      "source": [
        "y=labels['severe_toxic'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WcONuzIS93fc",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zils63KM_Zs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test['severe_toxic']=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HchcU9Qv93fj",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cznfG1he93fq",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions['severe_toxic'] = naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8SmQEz79c9b",
        "colab_type": "text"
      },
      "source": [
        "3. obscene class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TkJ7TD7F9-eS",
        "colab": {}
      },
      "source": [
        "y=labels['obscene'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBleN6oO9-eg",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tPVUK1j_lAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test['obscene']=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E1ARVgiv9-er",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cK4eDAX39-e2",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions['obscene'] = naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfjlVP9Q9gXm",
        "colab_type": "text"
      },
      "source": [
        "4. threat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aa2-_YvB-CRt",
        "colab": {}
      },
      "source": [
        "y=labels['threat'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kbXSSxsF-CR9",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh0PB5jY_48g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "Y_test['threat']=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SL36ONcd-CSN",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sCFvle5J-CSX",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions['threat'] = naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2TwTZ0H9hhy",
        "colab_type": "text"
      },
      "source": [
        "5. insult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_P1ZnN1-GDg",
        "colab": {}
      },
      "source": [
        "y=labels['insult'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9J7B59i_-GDu",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJhQplCwABdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test['insult']=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iz45znFU-GD7",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpBof3Ou-GEG",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions['insult'] = naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTkuS0Pw9ivi",
        "colab_type": "text"
      },
      "source": [
        "6. identity_hate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "irRu5zg2-Jo9",
        "colab": {}
      },
      "source": [
        "y=labels['identity_hate'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kjKMe6Zp-JpI",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X, y, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASlAM8XbAMdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test['identity_hate']=y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6kZD7trk-JpT",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abXE6YQg-Jpc",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions['identity_hate'] = naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIIbPvJz9kaD",
        "colab_type": "text"
      },
      "source": [
        "Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssul-T8P5VGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3f574c1f-4493-412b-81cb-18b08b43de61"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('Accuracy score: ', accuracy_score(Y_test, predictions))\n",
        "print('Precision score: ', precision_score(Y_test, predictions, average='micro'))\n",
        "print('Recall score: ', recall_score(Y_test, predictions, average='micro'))\n",
        "print('F1 score: ', f1_score(Y_test, predictions, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.79\n",
            "Precision score:  0.7\n",
            "Recall score:  0.1206896551724138\n",
            "F1 score:  0.2058823529411765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNWwZFJ9gym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHHeyfVfEhkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}